{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Data generation\n",
    "\n",
    "This notebook creates bash scripts that contain the commands to start each of the MML experiments to generate the predictions. To run the notebook and the actual experiments one needs to install the MML framework ('mml-core'). The 'mml-data' provides the necessary code to create the data locally. In addition the provided MML plugin for the data splitting tag needs to be installed ('mml-prevalences')."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____ ______   _____ ______   ___\n",
      "|\\   _ \\  _   \\|\\   _ \\  _   \\|\\  \\\n",
      "\\ \\  \\\\\\__\\ \\  \\ \\  \\\\\\__\\ \\  \\ \\  \\\n",
      " \\ \\  \\\\|__| \\  \\ \\  \\\\|__| \\  \\ \\  \\\n",
      "  \\ \\  \\    \\ \\  \\ \\  \\    \\ \\  \\ \\  \\____\n",
      "   \\ \\__\\    \\ \\__\\ \\__\\    \\ \\__\\ \\_______\\\n",
      "    \\|__|     \\|__|\\|__|     \\|__|\\|_______|\n",
      "         ____  _  _    __  _  _  ____  _  _\n",
      "        (  _ \\( \\/ )  (  )( \\/ )/ ___)( \\/ )\n",
      "         ) _ ( )  /    )( / \\/ \\\\___ \\ )  /\n",
      "        (____/(__/    (__)\\_)(_/(____/(__/\n",
      "Interactive MML API initialized.\n"
     ]
    }
   ],
   "source": [
    "import mml.api.interactive as nb\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "mml_env_path = Path(os.getcwd()).parent / 'mml.env'\n",
    "nb.init(mml_env_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-28T09:37:02.821310Z",
     "end_time": "2023-09-28T09:37:07.202575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "all_tasks = ['lapgyn4_surgical_actions', 'lapgyn4_instrument_count', 'lapgyn4_anatomical_actions', 'nerthus_bowel_cleansing_quality', 'hyperkvasir_therapeutic-interventions', 'cholec80_grasper_presence', 'cholec80_hook_presence', 'idle_action_recognition', 'brain_tumor_classification', 'brain_tumor_type_classification', 'chexpert_enlarged_cardiomediastinum', 'chexpert_cardiomegaly', 'chexpert_edema', 'chexpert_consolidation', 'chexpert_pneumonia', 'chexpert_pneumothorax', 'chexpert_pleural_effusion', 'chexpert_fracture', 'pneumonia_classification', 'covid_xray_classification', 'deep_drid_dr_level', 'deep_drid_quality', 'kvasir_capsule_anatomy', 'mura_xr_wrist', 'mura_xr_shoulder', 'mura_xr_humerus', 'mura_xr_hand', 'mura_xr_forearm', 'mura_xr_finger', 'mura_xr_elbow']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-28T09:37:11.058477Z",
     "end_time": "2023-09-28T09:37:11.060118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Configuration of the experiment surrounding\n",
    "# Option 1: Run on the LSF cluster\n",
    "cluster_reqs = nb.LSFSubmissionRequirements(\n",
    "    # the following is recommended\n",
    "    special_requirements=['tensorcore'],\n",
    "    num_gpus=1,\n",
    "    vram_per_gpu=11.0,\n",
    "    queue='gpu')\n",
    "# Option 2: run everything locally\n",
    "local_reqs = nb.DefaultRequirements()\n",
    "# Choose the option here\n",
    "reqs = local_reqs if True else cluster_reqs\n",
    "# recommended project folder and number of reruns\n",
    "project = 'mic23_predictions_reproduce'\n",
    "reruns = 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-28T09:37:12.467270Z",
     "end_time": "2023-09-28T09:37:12.469041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 1 commands at output_create.txt.\n",
      "Stored 30 commands at output_tag.txt.\n"
     ]
    }
   ],
   "source": [
    "# prepare steps\n",
    "create_cmds = list()\n",
    "tag_cmds = list()\n",
    "# step one: task creation\n",
    "create_cmds.append(nb.MMLJobDescription(prefix_req=reqs,\n",
    "                                      config_options={'mode': 'create', 'task_list': all_tasks, 'proj': project}))\n",
    "# step two: redistribute the splits\n",
    "for t in all_tasks:\n",
    "    tag_cmds.append(nb.MMLJobDescription(prefix_req=reqs,\n",
    "                                          config_options={'mode': 'info', 'task_list': [t], 'tagging.all': '+miccai?1337',\n",
    "                                                          'preprocessing': 'default',\n",
    "                                                          'proj': project}))\n",
    "nb.write_out_commands(cmd_list=create_cmds, suffix='create')\n",
    "nb.write_out_commands(cmd_list=tag_cmds, suffix='tag')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-28T09:37:13.663547Z",
     "end_time": "2023-09-28T09:37:13.667015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 90 commands at output_predict.txt.\n"
     ]
    }
   ],
   "source": [
    "base_cmds = list()\n",
    "for ix in range(reruns):\n",
    "    for t in all_tasks:\n",
    "        opts = {'mode': 'opt', 'mode.store_parameters': False, 'sampling.balanced': True,\n",
    "                       'sampling.batch_size': 300, 'callbacks': 'early', 'lr_scheduler': 'step',\n",
    "                       'trainer.max_epochs': 40, 'augmentations': 'baseline256', 'mode.val_is_test': False,\n",
    "                       'preprocessing': 'default_copy', 'trainer.min_epochs': 5}\n",
    "        opts.update(\n",
    "            {'proj': f'{project}_{ix}', 'seed': ix, 'mode.subroutines': '[train_fold,predict_val,predict_test]',\n",
    "             'task_list': [t],  'mode.store_parameters': True, 'tagging.all': '+miccai?1337', 'reuse.clean_up.parameters': True,\n",
    "             'lr_scheduler': 'plateau', 'lr_scheduler.patience': 5, '+callbacks.early.patience': 7})\n",
    "        base_cmds.append(nb.MMLJobDescription(prefix_req=reqs, config_options=opts))\n",
    "nb.write_out_commands(cmd_list=base_cmds, suffix='predict')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-28T09:37:15.098103Z",
     "end_time": "2023-09-28T09:37:15.105536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
