{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44cd748b401aa30a",
   "metadata": {},
   "source": [
    "## Uncertainty estimation\n",
    "\n",
    "This notebook inspects repeated experiments and tries to quantify the robustness of our experiments and methods."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:29:58.344948Z",
     "start_time": "2024-08-23T12:29:55.795426Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from progiter import ProgIter\n",
    "import torch.nn.functional as F\n",
    "from quapy.error import nkld\n",
    "from numpy.linalg import LinAlgError\n",
    "import quapy as qp\n",
    "from quapy.method.aggregative import CC, ACC, PCC, PACC, EMQ, KDEyCS, KDEyHD, KDEyML, DMy\n",
    "import IPython\n",
    "from src.prev.calibration import CalibrationMethod, calc_calibration_metrics, calibrate_logits_fast\n",
    "from src.prev.data_loading import get_values, Kind, Split, all_tasks, binary_tasks\n",
    "from src.prev.scaling import scale_prevalences_ir\n",
    "from src.prev.quantification import adjust_priors_qp, absolute_error, compute_w_hat_and_mu_hat, IdentityClassifier\n",
    "from src.prev.thresholding import ThresholdingMethod, find_best_thresholds\n",
    "from src.prev.metrics import Metric, compute_all_metrics, compute_metric\n",
    "\n",
    "current_path = os.getcwd()\n",
    "DATA_PATH = Path(current_path).parent / 'data'\n",
    "RESULT_PATH = Path(current_path).parent / 'results'\n",
    "assert DATA_PATH.exists() and RESULT_PATH.exists()\n",
    "torch.manual_seed(seed=0)\n",
    "# we only inspect a subset of imbalance ratios for performance reasons\n",
    "IRS = [1.0, 5.0, 10.]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e97a3623ed1c8300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:32:30.560325Z",
     "start_time": "2024-08-23T12:30:04.803070Z"
    }
   },
   "source": [
    "# load training/prediction data for 10 runs with varied random seed and 5 runs with varied data splitting seeds\n",
    "data = {}\n",
    "for repeat, proj in enumerate(\n",
    "        ['mic23_predictions_original_0', 'mic23_predictions_reproduce_0', 'mic23_predictions_reproduce_1',\n",
    "         'mic23_predictions_reproduce_2', 'mic23_predictions_reproduce_10', 'mic23_predictions_reproduce_11',\n",
    "         'mic23_predictions_reproduce_12', 'mic23_predictions_reproduce_13', 'mic23_predictions_reproduce_14',\n",
    "         'mic23_predictions_reproduce_15', 'mic23_predictions_datasplit_seed_3', 'mic23_predictions_datasplit_seed_31',\n",
    "         'mic23_predictions_datasplit_seed_314', 'mic23_predictions_datasplit_seed_3141',\n",
    "         'mic23_predictions_datasplit_seed_31415']):\n",
    "    data[repeat] = {}\n",
    "    for t in ProgIter(all_tasks, desc='Loading data'):\n",
    "        data[repeat][t] = get_values(t, DATA_PATH, proj=proj)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data 100.00% 30/30... rate=3.05 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.00 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=2.98 Hz, eta=0:00:00, total=0:00:10\n",
      "Loading data 100.00% 30/30... rate=2.99 Hz, eta=0:00:00, total=0:00:10\n",
      "Loading data 100.00% 30/30... rate=3.02 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.01 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.01 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.23 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.20 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.16 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.23 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.20 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=3.23 Hz, eta=0:00:00, total=0:00:09\n",
      "Loading data 100.00% 30/30... rate=2.98 Hz, eta=0:00:00, total=0:00:10\n",
      "Loading data 100.00% 30/30... rate=3.08 Hz, eta=0:00:00, total=0:00:09\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "db2f8229b14fdc02",
   "metadata": {},
   "source": [
    "## uncertainty with respect to quantification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "276d1ffb959fbe7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T14:10:41.199215Z",
     "start_time": "2024-08-22T12:26:14.160713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:52\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:47\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:47\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:58\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:53\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:07:04\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:07:08\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:07:03\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:07:03\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:07:03\n",
      " 66.67% 20/30... rate=0.05 Hz, eta=0:03:14, total=0:06:29[warning] the method has reached the maximum number of iterations; it might have not converged\n",
      "[warning] the method has reached the maximum number of iterations; it might have not converged\n",
      "[warning] the method has reached the maximum number of iterations; it might have not converged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scholzpa/miniconda3/envs/prevalences2024/lib/python3.10/site-packages/quapy/method/aggregative.py:933: RuntimeWarning: invalid value encountered in divide\n",
      "  distributions = counts/counts.sum(axis=1)[:,np.newaxis]\n",
      "/home/scholzpa/miniconda3/envs/prevalences2024/lib/python3.10/site-packages/quapy/method/aggregative.py:933: RuntimeWarning: invalid value encountered in divide\n",
      "  distributions = counts/counts.sum(axis=1)[:,np.newaxis]\n",
      "/home/scholzpa/miniconda3/envs/prevalences2024/lib/python3.10/site-packages/quapy/method/aggregative.py:933: RuntimeWarning: invalid value encountered in divide\n",
      "  distributions = counts/counts.sum(axis=1)[:,np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:47\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:49\n",
      " 66.67% 20/30... rate=0.05 Hz, eta=0:03:23, total=0:06:47[warning] the method has reached the maximum number of iterations; it might have not converged\n",
      "[warning] the method has reached the maximum number of iterations; it might have not converged\n",
      "[warning] the method has reached the maximum number of iterations; it might have not converged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scholzpa/miniconda3/envs/prevalences2024/lib/python3.10/site-packages/quapy/method/aggregative.py:933: RuntimeWarning: invalid value encountered in divide\n",
      "  distributions = counts/counts.sum(axis=1)[:,np.newaxis]\n",
      "/home/scholzpa/miniconda3/envs/prevalences2024/lib/python3.10/site-packages/quapy/method/aggregative.py:933: RuntimeWarning: invalid value encountered in divide\n",
      "  distributions = counts/counts.sum(axis=1)[:,np.newaxis]\n",
      "/home/scholzpa/miniconda3/envs/prevalences2024/lib/python3.10/site-packages/quapy/method/aggregative.py:933: RuntimeWarning: invalid value encountered in divide\n",
      "  distributions = counts/counts.sum(axis=1)[:,np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:07:05\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:07:02\n",
      " 100.00% 30/30... rate=0.07 Hz, eta=0:00:00, total=0:06:58\n"
     ]
    }
   ],
   "source": [
    "uncertainty_quantification_results = []\n",
    "for repeat in data:\n",
    "    for t in ProgIter(all_tasks):\n",
    "        task_data = data[repeat][t]\n",
    "        for ir in IRS:\n",
    "            # modify DEV_TEST according to IR\n",
    "            try:\n",
    "                app_test_logits, app_test_classes = scale_prevalences_ir(logits=task_data[Kind.LOGITS][Split.APP_TEST],\n",
    "                                                                         classes=task_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                                                         ir=ir)\n",
    "            except:\n",
    "                print(f'{t=}, {ir=}')\n",
    "                raise\n",
    "            mod_data = {Kind.LOGITS: {Split.DEV_CAL: task_data[Kind.LOGITS][Split.DEV_CAL],\n",
    "                                      Split.DEV_TEST: task_data[Kind.LOGITS][Split.DEV_TEST],\n",
    "                                      Split.APP_TEST: app_test_logits},\n",
    "                        Kind.LABELS: {Split.DEV_CAL: task_data[Kind.LABELS][Split.DEV_CAL],\n",
    "                                      Split.DEV_TEST: task_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                      Split.APP_TEST: app_test_classes}}\n",
    "            # estimate prevalence using BBSE\n",
    "            try:\n",
    "                _, bbse_prior = compute_w_hat_and_mu_hat(mod_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                                         torch.argmax(mod_data[Kind.LOGITS][Split.DEV_TEST], dim=1),\n",
    "                                                         torch.argmax(mod_data[Kind.LOGITS][Split.APP_TEST], dim=1))\n",
    "            except LinAlgError:\n",
    "                bbse_prior = None\n",
    "            prior = (torch.bincount(app_test_classes) / len(app_test_classes)).numpy()\n",
    "            d_size = len(app_test_classes)\n",
    "            _info = {'ir': ir, 'task': t, 'repeat': repeat}\n",
    "            _info.update({\"BBSE\": bbse_prior})\n",
    "            _info.update({\"prior\": prior})\n",
    "            _info.update({\"d_size\": d_size})\n",
    "            # convert data to qp format\n",
    "            dev_data = qp.data.LabelledCollection(torch.softmax(mod_data[Kind.LOGITS][Split.DEV_TEST], dim=1),\n",
    "                                                  mod_data[Kind.LABELS][Split.DEV_TEST])\n",
    "            app_data = qp.data.LabelledCollection(torch.softmax(mod_data[Kind.LOGITS][Split.APP_TEST], dim=1),\n",
    "                                                  mod_data[Kind.LABELS][Split.APP_TEST])\n",
    "            dset = qp.data.base.Dataset(training=dev_data, test=app_data)\n",
    "            # compute estimated prevalences with methods from qp\n",
    "            for method_name, method in {\"CC\": CC, \"ACC\": ACC, \"PCC\": PCC, \"PACC\": PACC, \"EMQ\": EMQ, \"HDy\": DMy,\n",
    "                                        'KDEyCS': KDEyCS, 'KDEyHD': KDEyHD, 'KDEyML': KDEyML}.items():\n",
    "                identity_class = IdentityClassifier(len(prior))\n",
    "                model = method(identity_class)\n",
    "                try:  # data[10][all_tasks[20]] is corrupted\n",
    "                    model.fit(dset.training)\n",
    "                    estim_prevalence = model.quantify(dset.test.instances)\n",
    "                    _info.update({method_name: estim_prevalence})\n",
    "                except ValueError:\n",
    "                    _info.update({method_name: None})\n",
    "            uncertainty_quantification_results.append(_info)\n",
    "quantification_df = pd.DataFrame(uncertainty_quantification_results)\n",
    "quantification_df.to_pickle(RESULT_PATH / '24_uncertainty_quantification.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "id": "738238c608d46cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:32:31.479971Z",
     "start_time": "2024-08-23T12:32:30.562036Z"
    }
   },
   "source": [
    "quantification_df = pd.read_pickle(RESULT_PATH / '24_uncertainty_quantification.pkl').fillna(value=np.nan)\n",
    "table_entries = []\n",
    "_methods = ['BBSE', \"CC\", \"ACC\", \"PCC\", \"PACC\", \"EMQ\", \"HDy\", 'KDEyCS', 'KDEyHD', 'KDEyML']\n",
    "_metrics = metrics = {\"Absolute error\": absolute_error, \"Normalized KLD\": nkld}\n",
    "for ir in IRS:\n",
    "    for method in _methods:\n",
    "        train_uncertainty = {met: [] for met in _metrics}\n",
    "        data_uncertainty = {met: [] for met in _metrics}\n",
    "        for repeat in data:\n",
    "            vals = train_uncertainty if repeat < 10 else data_uncertainty\n",
    "            sub_df = quantification_df[(quantification_df.ir == ir) & (quantification_df.repeat == repeat)]\n",
    "            for met in _metrics:\n",
    "                # apply metric to all tasks (of this IR and repeat)\n",
    "                if met == \"Normalized KLD\":\n",
    "                    metric_series = sub_df.apply(\n",
    "                        lambda row: _metrics[met](row['prior'], row[method], eps=1 / row['d_size']), axis=1)\n",
    "                else:\n",
    "                    metric_series = sub_df.apply(lambda row: _metrics[met](row['prior'], row[method]), axis=1)\n",
    "                # average over tasks\n",
    "                vals[met].append(metric_series.mean())\n",
    "        _info = {'ir': ir, 'method': method}\n",
    "        for met in _metrics:\n",
    "            # average over all repeats\n",
    "            _info[met] = (f'{np.mean(train_uncertainty[met]):.3f} ± {np.std(train_uncertainty[met]):.3f} | '\n",
    "                          f'{np.mean(data_uncertainty[met]):.3f} ± {np.std(data_uncertainty[met]):.3f}')\n",
    "        table_entries.append(_info)\n",
    "quantification_table_df = pd.DataFrame(table_entries)\n",
    "print('Uncertainty with respect to quantification: Absolute error')\n",
    "quantification_table_df.pivot(columns='ir', index='method', values='Absolute error')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty with respect to quantification: Absolute error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ir                               1.0                            5.0   \\\n",
       "method                                                                 \n",
       "ACC     0.085 ± 0.026 | 0.073 ± 0.021  0.104 ± 0.039 | 0.133 ± 0.023   \n",
       "BBSE    0.127 ± 0.134 | 0.084 ± 0.031  0.087 ± 0.053 | 0.104 ± 0.074   \n",
       "CC      0.238 ± 0.072 | 0.306 ± 0.028  0.190 ± 0.066 | 0.259 ± 0.040   \n",
       "EMQ     0.363 ± 0.084 | 0.397 ± 0.019  0.234 ± 0.076 | 0.288 ± 0.039   \n",
       "HDy     0.071 ± 0.021 | 0.082 ± 0.019  0.102 ± 0.031 | 0.115 ± 0.013   \n",
       "KDEyCS  0.065 ± 0.017 | 0.060 ± 0.021  0.097 ± 0.028 | 0.105 ± 0.015   \n",
       "KDEyHD  0.060 ± 0.015 | 0.054 ± 0.015  0.094 ± 0.030 | 0.102 ± 0.010   \n",
       "KDEyML  0.152 ± 0.078 | 0.200 ± 0.046  0.168 ± 0.091 | 0.201 ± 0.058   \n",
       "PACC    0.086 ± 0.022 | 0.087 ± 0.027  0.102 ± 0.032 | 0.109 ± 0.008   \n",
       "PCC     0.139 ± 0.022 | 0.162 ± 0.018  0.210 ± 0.029 | 0.241 ± 0.027   \n",
       "\n",
       "ir                               10.0  \n",
       "method                                 \n",
       "ACC     0.116 ± 0.043 | 0.150 ± 0.031  \n",
       "BBSE    0.101 ± 0.079 | 0.099 ± 0.062  \n",
       "CC      0.220 ± 0.062 | 0.288 ± 0.044  \n",
       "EMQ     0.193 ± 0.076 | 0.256 ± 0.042  \n",
       "HDy     0.118 ± 0.043 | 0.132 ± 0.025  \n",
       "KDEyCS  0.111 ± 0.040 | 0.128 ± 0.020  \n",
       "KDEyHD  0.106 ± 0.040 | 0.121 ± 0.019  \n",
       "KDEyML  0.171 ± 0.091 | 0.199 ± 0.070  \n",
       "PACC    0.109 ± 0.040 | 0.135 ± 0.015  \n",
       "PCC     0.277 ± 0.035 | 0.313 ± 0.030  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ir</th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.085 ± 0.026 | 0.073 ± 0.021</td>\n",
       "      <td>0.104 ± 0.039 | 0.133 ± 0.023</td>\n",
       "      <td>0.116 ± 0.043 | 0.150 ± 0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBSE</th>\n",
       "      <td>0.127 ± 0.134 | 0.084 ± 0.031</td>\n",
       "      <td>0.087 ± 0.053 | 0.104 ± 0.074</td>\n",
       "      <td>0.101 ± 0.079 | 0.099 ± 0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.238 ± 0.072 | 0.306 ± 0.028</td>\n",
       "      <td>0.190 ± 0.066 | 0.259 ± 0.040</td>\n",
       "      <td>0.220 ± 0.062 | 0.288 ± 0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMQ</th>\n",
       "      <td>0.363 ± 0.084 | 0.397 ± 0.019</td>\n",
       "      <td>0.234 ± 0.076 | 0.288 ± 0.039</td>\n",
       "      <td>0.193 ± 0.076 | 0.256 ± 0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDy</th>\n",
       "      <td>0.071 ± 0.021 | 0.082 ± 0.019</td>\n",
       "      <td>0.102 ± 0.031 | 0.115 ± 0.013</td>\n",
       "      <td>0.118 ± 0.043 | 0.132 ± 0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDEyCS</th>\n",
       "      <td>0.065 ± 0.017 | 0.060 ± 0.021</td>\n",
       "      <td>0.097 ± 0.028 | 0.105 ± 0.015</td>\n",
       "      <td>0.111 ± 0.040 | 0.128 ± 0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDEyHD</th>\n",
       "      <td>0.060 ± 0.015 | 0.054 ± 0.015</td>\n",
       "      <td>0.094 ± 0.030 | 0.102 ± 0.010</td>\n",
       "      <td>0.106 ± 0.040 | 0.121 ± 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDEyML</th>\n",
       "      <td>0.152 ± 0.078 | 0.200 ± 0.046</td>\n",
       "      <td>0.168 ± 0.091 | 0.201 ± 0.058</td>\n",
       "      <td>0.171 ± 0.091 | 0.199 ± 0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PACC</th>\n",
       "      <td>0.086 ± 0.022 | 0.087 ± 0.027</td>\n",
       "      <td>0.102 ± 0.032 | 0.109 ± 0.008</td>\n",
       "      <td>0.109 ± 0.040 | 0.135 ± 0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.139 ± 0.022 | 0.162 ± 0.018</td>\n",
       "      <td>0.210 ± 0.029 | 0.241 ± 0.027</td>\n",
       "      <td>0.277 ± 0.035 | 0.313 ± 0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a2a107f556fb0ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:32:33.168731Z",
     "start_time": "2024-08-23T12:32:33.158469Z"
    }
   },
   "source": [
    "print('Uncertainty with respect to quantification: Normalized KLD')\n",
    "quantification_table_df.pivot(columns='ir', index='method', values='Normalized KLD')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty with respect to quantification: Normalized KLD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ir                               1.0                            5.0   \\\n",
       "method                                                                 \n",
       "ACC     0.020 ± 0.018 | 0.013 ± 0.012  0.022 ± 0.020 | 0.033 ± 0.016   \n",
       "BBSE    0.019 ± 0.018 | 0.014 ± 0.013  0.013 ± 0.011 | 0.021 ± 0.016   \n",
       "CC      0.066 ± 0.041 | 0.113 ± 0.021  0.059 ± 0.040 | 0.102 ± 0.021   \n",
       "EMQ     0.153 ± 0.063 | 0.191 ± 0.025  0.126 ± 0.055 | 0.160 ± 0.025   \n",
       "HDy     0.012 ± 0.010 | 0.026 ± 0.016  0.019 ± 0.011 | 0.025 ± 0.005   \n",
       "KDEyCS  0.009 ± 0.010 | 0.008 ± 0.007  0.015 ± 0.006 | 0.017 ± 0.005   \n",
       "KDEyHD  0.008 ± 0.010 | 0.005 ± 0.004  0.013 ± 0.007 | 0.020 ± 0.008   \n",
       "KDEyML  0.065 ± 0.049 | 0.106 ± 0.035  0.070 ± 0.054 | 0.105 ± 0.034   \n",
       "PACC    0.026 ± 0.015 | 0.016 ± 0.013  0.025 ± 0.013 | 0.023 ± 0.008   \n",
       "PCC     0.013 ± 0.005 | 0.027 ± 0.009  0.026 ± 0.009 | 0.042 ± 0.011   \n",
       "\n",
       "ir                               10.0  \n",
       "method                                 \n",
       "ACC     0.030 ± 0.016 | 0.042 ± 0.016  \n",
       "BBSE    0.020 ± 0.013 | 0.020 ± 0.014  \n",
       "CC      0.063 ± 0.037 | 0.106 ± 0.022  \n",
       "EMQ     0.103 ± 0.047 | 0.136 ± 0.026  \n",
       "HDy     0.029 ± 0.017 | 0.032 ± 0.007  \n",
       "KDEyCS  0.025 ± 0.013 | 0.031 ± 0.006  \n",
       "KDEyHD  0.020 ± 0.012 | 0.031 ± 0.004  \n",
       "KDEyML  0.075 ± 0.053 | 0.101 ± 0.039  \n",
       "PACC    0.031 ± 0.018 | 0.041 ± 0.007  \n",
       "PCC     0.047 ± 0.013 | 0.064 ± 0.012  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ir</th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.020 ± 0.018 | 0.013 ± 0.012</td>\n",
       "      <td>0.022 ± 0.020 | 0.033 ± 0.016</td>\n",
       "      <td>0.030 ± 0.016 | 0.042 ± 0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBSE</th>\n",
       "      <td>0.019 ± 0.018 | 0.014 ± 0.013</td>\n",
       "      <td>0.013 ± 0.011 | 0.021 ± 0.016</td>\n",
       "      <td>0.020 ± 0.013 | 0.020 ± 0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.066 ± 0.041 | 0.113 ± 0.021</td>\n",
       "      <td>0.059 ± 0.040 | 0.102 ± 0.021</td>\n",
       "      <td>0.063 ± 0.037 | 0.106 ± 0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMQ</th>\n",
       "      <td>0.153 ± 0.063 | 0.191 ± 0.025</td>\n",
       "      <td>0.126 ± 0.055 | 0.160 ± 0.025</td>\n",
       "      <td>0.103 ± 0.047 | 0.136 ± 0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDy</th>\n",
       "      <td>0.012 ± 0.010 | 0.026 ± 0.016</td>\n",
       "      <td>0.019 ± 0.011 | 0.025 ± 0.005</td>\n",
       "      <td>0.029 ± 0.017 | 0.032 ± 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDEyCS</th>\n",
       "      <td>0.009 ± 0.010 | 0.008 ± 0.007</td>\n",
       "      <td>0.015 ± 0.006 | 0.017 ± 0.005</td>\n",
       "      <td>0.025 ± 0.013 | 0.031 ± 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDEyHD</th>\n",
       "      <td>0.008 ± 0.010 | 0.005 ± 0.004</td>\n",
       "      <td>0.013 ± 0.007 | 0.020 ± 0.008</td>\n",
       "      <td>0.020 ± 0.012 | 0.031 ± 0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDEyML</th>\n",
       "      <td>0.065 ± 0.049 | 0.106 ± 0.035</td>\n",
       "      <td>0.070 ± 0.054 | 0.105 ± 0.034</td>\n",
       "      <td>0.075 ± 0.053 | 0.101 ± 0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PACC</th>\n",
       "      <td>0.026 ± 0.015 | 0.016 ± 0.013</td>\n",
       "      <td>0.025 ± 0.013 | 0.023 ± 0.008</td>\n",
       "      <td>0.031 ± 0.018 | 0.041 ± 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.013 ± 0.005 | 0.027 ± 0.009</td>\n",
       "      <td>0.026 ± 0.009 | 0.042 ± 0.011</td>\n",
       "      <td>0.047 ± 0.013 | 0.064 ± 0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "8cc5cbf72d4fa42a",
   "metadata": {},
   "source": [
    "## uncertainty with respect to re-calibration"
   ]
  },
  {
   "cell_type": "code",
   "id": "4fe2b00e2ed1bdc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:32:41.048490Z",
     "start_time": "2024-08-23T12:32:41.044076Z"
    }
   },
   "source": [
    "def get_estimated_prevalences(task_data: Dict[Kind, Dict[Split, torch.Tensor]]) -> torch.Tensor:\n",
    "    estimated_prevalence = adjust_priors_qp(torch.softmax(task_data[Kind.LOGITS][Split.DEV_TEST], dim=1),\n",
    "                                            task_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                            torch.softmax(task_data[Kind.LOGITS][Split.APP_TEST], dim=1),\n",
    "                                            task_data[Kind.LABELS][Split.APP_TEST])\n",
    "    return estimated_prevalence"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410be14464a6af12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:09:51.900080Z",
     "start_time": "2024-08-21T16:06:15.626802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00% 12/12... rate=0.06 Hz, eta=0:00:00, total=0:03:36\n"
     ]
    }
   ],
   "source": [
    "calibration_ir_results = []\n",
    "for cal_method in ProgIter(list(CalibrationMethod)[:]):\n",
    "    if cal_method in [CalibrationMethod.ADAPTED_TRAIN_WEIGHTS,\n",
    "                      CalibrationMethod.ADAPTED_TRAIN_WEIGHTS_AND_AFFINE_SCALING_REWEIGHTED,\n",
    "                      CalibrationMethod.ADAPTED_TRAIN_WEIGHTS_AND_TEMPERATURE_SCALING_REWEIGHTED,\n",
    "                      CalibrationMethod.ADAPTED_TRAIN_WEIGHTS_ACC,\n",
    "                      CalibrationMethod.ADAPTED_TRAIN_WEIGHTS_AND_AFFINE_SCALING_REWEIGHETD_ACC,\n",
    "                      CalibrationMethod.ADAPTED_TRAIN_WEIGHTS_AND_TEMPERATURE_SCALING_REWEIGHTED_ACC]:\n",
    "        # no repeated experiments for adapted train weights (due to high computational costs)\n",
    "        continue\n",
    "    for ir in IRS:\n",
    "        for repeat in data:\n",
    "            # do the calibration on all tasks\n",
    "            calibrated_test_data: Dict[str, Dict[Kind, Dict[Split, torch.Tensor]]] = {}\n",
    "            for t in all_tasks:\n",
    "                # STEP 1: modify DEV_TEST according to IR\n",
    "                task_data = data[repeat][t]\n",
    "                app_test_logits, app_test_classes = scale_prevalences_ir(logits=task_data[Kind.LOGITS][Split.APP_TEST],\n",
    "                                                                         classes=task_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                                                         ir=ir)\n",
    "                mod_data = {Kind.LOGITS: {Split.DEV_CAL: task_data[Kind.LOGITS][Split.DEV_CAL],\n",
    "                                          Split.DEV_TEST: task_data[Kind.LOGITS][Split.DEV_TEST],\n",
    "                                          Split.APP_TEST: app_test_logits},\n",
    "                            Kind.LABELS: {Split.DEV_CAL: task_data[Kind.LABELS][Split.DEV_CAL],\n",
    "                                          Split.DEV_TEST: task_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                          Split.APP_TEST: app_test_classes}}\n",
    "                # STEP 2: determine prior knowledge\n",
    "                prior = None  # by default, we know nothing\n",
    "                if cal_method in [CalibrationMethod.AFFINE_REWEIGHTED,\n",
    "                                  CalibrationMethod.TEMPERATURE_SCALING_REWEIGHTED]:\n",
    "                    # adapt prevalences from DEV_CAL to APP_TEST (the latter is balanced)\n",
    "                    prior = torch.bincount(app_test_classes)\n",
    "                    # scaling for convergence stability\n",
    "                    prior = prior / prior.sum()\n",
    "                elif cal_method in [CalibrationMethod.AFFINE_ACC]:\n",
    "                    prior = get_estimated_prevalences(task_data=mod_data)\n",
    "                # STEP 3: re-calibrate\n",
    "                calibrated_logits = calibrate_logits_fast(data=mod_data, calibration=cal_method, prior=prior)\n",
    "                # STEP 4: calculate calibration metrics\n",
    "                # suppress plotting from the metrics reloaded\n",
    "                with IPython.utils.io.capture_output():\n",
    "                    dev_metrics = calc_calibration_metrics(logits=calibrated_logits[Split.DEV_TEST],\n",
    "                                                           labels=task_data[Kind.LABELS][Split.DEV_TEST])\n",
    "                    app_metrics = calc_calibration_metrics(logits=calibrated_logits[Split.APP_TEST],\n",
    "                                                           labels=app_test_classes)\n",
    "                # going from dev to test\n",
    "                diff_metrics = {m: app_metrics[m] - dev_metrics[m] for m in dev_metrics}\n",
    "                _info = {'calibration': cal_method.name, 'ir': ir, 'task': t, 'repeat': repeat}\n",
    "                _info.update({f'dev_{m}': v for m, v in dev_metrics.items()})\n",
    "                _info.update({f'app_{m}': v for m, v in app_metrics.items()})\n",
    "                _info.update({f'diff_{m}': v for m, v in diff_metrics.items()})\n",
    "                calibration_ir_results.append(_info)\n",
    "calibration_df = pd.DataFrame(calibration_ir_results)\n",
    "calibration_df.to_csv(RESULT_PATH / '24_uncertainty_calibration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "id": "c63e67772eef042b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:33:34.366055Z",
     "start_time": "2024-08-23T12:33:34.202702Z"
    }
   },
   "source": [
    "calibration_df = pd.read_csv(RESULT_PATH / '24_uncertainty_calibration.csv')\n",
    "table_entries = []\n",
    "_metrics = ['app_cwce', 'app_bs']\n",
    "for ir in IRS:\n",
    "    for method in calibration_df.calibration.unique():\n",
    "        sub_df = calibration_df[(calibration_df.calibration == method) & (calibration_df.ir == ir)]\n",
    "        train_uncertainty = {met: [] for met in _metrics}\n",
    "        data_uncertainty = {met: [] for met in _metrics}\n",
    "        for repeat in sub_df['repeat'].unique():\n",
    "            vals = train_uncertainty if repeat < 10 else data_uncertainty\n",
    "            for met in _metrics:\n",
    "                vals[met].append(sub_df[sub_df['repeat'] == repeat][met].mean())\n",
    "        _info = {'ir': ir, 'method': method}\n",
    "        for met in _metrics:\n",
    "            _info[met] = (f'{np.mean(train_uncertainty[met]):.3f} ± {np.std(train_uncertainty[met]):.3f} | '\n",
    "                          f'{np.mean(data_uncertainty[met]):.3f} ± {np.std(data_uncertainty[met]):.3f}')\n",
    "        table_entries.append(_info)\n",
    "df = pd.DataFrame(table_entries)\n",
    "enum_map = {elem.name: elem.value for elem in list(CalibrationMethod)}\n",
    "print(f'Uncertainty with respect to re-calibration: CWCE')\n",
    "df.replace(enum_map).pivot(columns='ir', index='method', values='app_cwce')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty with respect to re-calibration: CWCE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ir                                              1.0   \\\n",
       "method                                                 \n",
       "Affine                 0.078 ± 0.004 | 0.077 ± 0.003   \n",
       "Affine (dep. prev.)    0.026 ± 0.002 | 0.024 ± 0.001   \n",
       "Affine (est. prev.)    0.041 ± 0.009 | 0.040 ± 0.008   \n",
       "No re-calibration      0.071 ± 0.005 | 0.073 ± 0.007   \n",
       "TempScal               0.058 ± 0.005 | 0.059 ± 0.004   \n",
       "TempScal (dep. prev.)  0.047 ± 0.003 | 0.045 ± 0.005   \n",
       "\n",
       "ir                                              5.0   \\\n",
       "method                                                 \n",
       "Affine                 0.077 ± 0.002 | 0.076 ± 0.002   \n",
       "Affine (dep. prev.)    0.018 ± 0.001 | 0.016 ± 0.002   \n",
       "Affine (est. prev.)    0.041 ± 0.011 | 0.047 ± 0.010   \n",
       "No re-calibration      0.094 ± 0.008 | 0.098 ± 0.007   \n",
       "TempScal               0.099 ± 0.006 | 0.098 ± 0.007   \n",
       "TempScal (dep. prev.)  0.088 ± 0.007 | 0.089 ± 0.008   \n",
       "\n",
       "ir                                              10.0  \n",
       "method                                                \n",
       "Affine                 0.108 ± 0.004 | 0.108 ± 0.001  \n",
       "Affine (dep. prev.)    0.013 ± 0.001 | 0.012 ± 0.001  \n",
       "Affine (est. prev.)    0.041 ± 0.012 | 0.049 ± 0.011  \n",
       "No re-calibration      0.122 ± 0.009 | 0.127 ± 0.008  \n",
       "TempScal               0.131 ± 0.007 | 0.131 ± 0.007  \n",
       "TempScal (dep. prev.)  0.111 ± 0.008 | 0.113 ± 0.009  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ir</th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Affine</th>\n",
       "      <td>0.078 ± 0.004 | 0.077 ± 0.003</td>\n",
       "      <td>0.077 ± 0.002 | 0.076 ± 0.002</td>\n",
       "      <td>0.108 ± 0.004 | 0.108 ± 0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affine (dep. prev.)</th>\n",
       "      <td>0.026 ± 0.002 | 0.024 ± 0.001</td>\n",
       "      <td>0.018 ± 0.001 | 0.016 ± 0.002</td>\n",
       "      <td>0.013 ± 0.001 | 0.012 ± 0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affine (est. prev.)</th>\n",
       "      <td>0.041 ± 0.009 | 0.040 ± 0.008</td>\n",
       "      <td>0.041 ± 0.011 | 0.047 ± 0.010</td>\n",
       "      <td>0.041 ± 0.012 | 0.049 ± 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No re-calibration</th>\n",
       "      <td>0.071 ± 0.005 | 0.073 ± 0.007</td>\n",
       "      <td>0.094 ± 0.008 | 0.098 ± 0.007</td>\n",
       "      <td>0.122 ± 0.009 | 0.127 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TempScal</th>\n",
       "      <td>0.058 ± 0.005 | 0.059 ± 0.004</td>\n",
       "      <td>0.099 ± 0.006 | 0.098 ± 0.007</td>\n",
       "      <td>0.131 ± 0.007 | 0.131 ± 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TempScal (dep. prev.)</th>\n",
       "      <td>0.047 ± 0.003 | 0.045 ± 0.005</td>\n",
       "      <td>0.088 ± 0.007 | 0.089 ± 0.008</td>\n",
       "      <td>0.111 ± 0.008 | 0.113 ± 0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "3e1e659dd8186200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:33:40.592241Z",
     "start_time": "2024-08-23T12:33:40.580348Z"
    }
   },
   "source": [
    "print(f'Uncertainty with respect to re-calibration: Brier Score')\n",
    "df.replace(enum_map).pivot(columns='ir', index='method', values='app_bs')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty with respect to re-calibration: Brier Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ir                                              1.0   \\\n",
       "method                                                 \n",
       "Affine                 0.124 ± 0.008 | 0.127 ± 0.003   \n",
       "Affine (dep. prev.)    0.112 ± 0.007 | 0.115 ± 0.002   \n",
       "Affine (est. prev.)    0.117 ± 0.009 | 0.119 ± 0.005   \n",
       "No re-calibration      0.121 ± 0.008 | 0.126 ± 0.003   \n",
       "TempScal               0.118 ± 0.008 | 0.122 ± 0.002   \n",
       "TempScal (dep. prev.)  0.116 ± 0.007 | 0.119 ± 0.002   \n",
       "\n",
       "ir                                              5.0   \\\n",
       "method                                                 \n",
       "Affine                 0.086 ± 0.006 | 0.088 ± 0.002   \n",
       "Affine (dep. prev.)    0.072 ± 0.005 | 0.073 ± 0.002   \n",
       "Affine (est. prev.)    0.078 ± 0.009 | 0.086 ± 0.010   \n",
       "No re-calibration      0.095 ± 0.007 | 0.100 ± 0.005   \n",
       "TempScal               0.094 ± 0.006 | 0.096 ± 0.004   \n",
       "TempScal (dep. prev.)  0.092 ± 0.006 | 0.095 ± 0.004   \n",
       "\n",
       "ir                                              10.0  \n",
       "method                                                \n",
       "Affine                 0.078 ± 0.005 | 0.079 ± 0.002  \n",
       "Affine (dep. prev.)    0.049 ± 0.004 | 0.050 ± 0.002  \n",
       "Affine (est. prev.)    0.057 ± 0.008 | 0.066 ± 0.012  \n",
       "No re-calibration      0.089 ± 0.008 | 0.094 ± 0.006  \n",
       "TempScal               0.088 ± 0.006 | 0.090 ± 0.005  \n",
       "TempScal (dep. prev.)  0.085 ± 0.006 | 0.087 ± 0.005  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ir</th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Affine</th>\n",
       "      <td>0.124 ± 0.008 | 0.127 ± 0.003</td>\n",
       "      <td>0.086 ± 0.006 | 0.088 ± 0.002</td>\n",
       "      <td>0.078 ± 0.005 | 0.079 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affine (dep. prev.)</th>\n",
       "      <td>0.112 ± 0.007 | 0.115 ± 0.002</td>\n",
       "      <td>0.072 ± 0.005 | 0.073 ± 0.002</td>\n",
       "      <td>0.049 ± 0.004 | 0.050 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affine (est. prev.)</th>\n",
       "      <td>0.117 ± 0.009 | 0.119 ± 0.005</td>\n",
       "      <td>0.078 ± 0.009 | 0.086 ± 0.010</td>\n",
       "      <td>0.057 ± 0.008 | 0.066 ± 0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No re-calibration</th>\n",
       "      <td>0.121 ± 0.008 | 0.126 ± 0.003</td>\n",
       "      <td>0.095 ± 0.007 | 0.100 ± 0.005</td>\n",
       "      <td>0.089 ± 0.008 | 0.094 ± 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TempScal</th>\n",
       "      <td>0.118 ± 0.008 | 0.122 ± 0.002</td>\n",
       "      <td>0.094 ± 0.006 | 0.096 ± 0.004</td>\n",
       "      <td>0.088 ± 0.006 | 0.090 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TempScal (dep. prev.)</th>\n",
       "      <td>0.116 ± 0.007 | 0.119 ± 0.002</td>\n",
       "      <td>0.092 ± 0.006 | 0.095 ± 0.004</td>\n",
       "      <td>0.085 ± 0.006 | 0.087 ± 0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "ba3e2ca0d163dad7",
   "metadata": {},
   "source": [
    "## uncertainty with respect to decision rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4dd57cf6429b5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:11:50.204688Z",
     "start_time": "2024-08-21T16:11:50.188373Z"
    }
   },
   "outputs": [],
   "source": [
    "def thresholds_accross_ir(task_data, calibration: CalibrationMethod = CalibrationMethod.NONE,\n",
    "                          thresholding: ThresholdingMethod = ThresholdingMethod.ARGMAX):\n",
    "    \"\"\"\n",
    "    Computes the values of metrics for optimal thresholds computed for the application test set and\n",
    "    thresholds set on the development test set for a given task across imbalance ratios.\n",
    "\n",
    "    :param task_data:\n",
    "    :param calibration: calibration method\n",
    "    :param thresholding: thresholding method to be used\n",
    "    :return results: dictionary of metric values\n",
    "    \"\"\"\n",
    "    # initialize the results dictionary\n",
    "    results = {m: [] for m in Metric}\n",
    "    results.update({\"reference \" + m.value: [] for m in Metric})\n",
    "    for ir in IRS:\n",
    "        # scale prevalences in the deployment set according to imbalance ratio\n",
    "        app_test_logits, app_test_classes = scale_prevalences_ir(logits=task_data[Kind.LOGITS][Split.APP_TEST],\n",
    "                                                                 classes=task_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                                                 ir=ir)\n",
    "        # create a data dictionary with the modified deployment test set\n",
    "        mod_data = {Kind.LOGITS: {Split.DEV_CAL: task_data[Kind.LOGITS][Split.DEV_CAL],\n",
    "                                  Split.DEV_TEST: task_data[Kind.LOGITS][Split.DEV_TEST],\n",
    "                                  Split.APP_TEST: app_test_logits},\n",
    "                    Kind.LABELS: {Split.DEV_CAL: task_data[Kind.LABELS][Split.DEV_CAL],\n",
    "                                  Split.DEV_TEST: task_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                  Split.APP_TEST: app_test_classes}}\n",
    "        # compute the number of samples in each class of the app test set with modified prevalence\n",
    "        exact_prevalence = torch.bincount(mod_data[Kind.LABELS][Split.APP_TEST]) / len(mod_data[Kind.LABELS][Split.APP_TEST])\n",
    "        # estimated version of these prevalences\n",
    "        estimated_prevalence = torch.Tensor(\n",
    "            adjust_priors_qp(torch.softmax(mod_data[Kind.LOGITS][Split.DEV_TEST], dim=1),\n",
    "                             mod_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                             torch.softmax(mod_data[Kind.LOGITS][Split.APP_TEST], dim=1),\n",
    "                             mod_data[Kind.LABELS][Split.APP_TEST]))\n",
    "        if calibration == CalibrationMethod.AFFINE_REWEIGHTED:\n",
    "            # define exact prior to use if calibrating using real priors\n",
    "            prior = exact_prevalence\n",
    "        elif calibration == CalibrationMethod.AFFINE_ACC:\n",
    "            prior = estimated_prevalence\n",
    "        elif calibration == CalibrationMethod.NONE:\n",
    "            prior = None\n",
    "        else:\n",
    "            raise ValueError('calibration method not supported')\n",
    "        calibrated_logits = calibrate_logits_fast(data=mod_data, calibration=calibration, prior=prior)\n",
    "        # extract the minority class for F1 computation\n",
    "        val_prevalences = torch.bincount(mod_data[Kind.LABELS][Split.DEV_CAL])\n",
    "        min_class = torch.argmin(val_prevalences).item()\n",
    "        max_class = torch.argmax(val_prevalences).item()\n",
    "        # catches case where for balanced task, min class was used as max class in scaling\n",
    "        if min_class == max_class:\n",
    "            min_class = 1\n",
    "        if thresholding == ThresholdingMethod.ARGMAX:\n",
    "            # use 0.5 as threshold (argmax)\n",
    "            thresholds = {m: 0.5 for m in Metric}\n",
    "        elif thresholding == ThresholdingMethod.DEV_TEST:\n",
    "            # find optimal thresholds on dev test\n",
    "            thresholds = find_best_thresholds(labels=mod_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                              logits=calibrated_logits[Split.DEV_TEST], min_class=min_class,\n",
    "                                              priors=exact_prevalence.numpy(),\n",
    "                                              est_priors=estimated_prevalence.numpy())\n",
    "        else:\n",
    "            raise ValueError('invalid thresholding method')\n",
    "        # find optimal thresholds on app test\n",
    "        optimal_thresholds = find_best_thresholds(labels=mod_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                                  logits=calibrated_logits[Split.APP_TEST], min_class=min_class,\n",
    "                                                  priors=exact_prevalence.numpy(),\n",
    "                                                  est_priors=estimated_prevalence.numpy())\n",
    "        # compute  predictions on app test using the two sets of thresholds                                        \n",
    "        new_app_test_preds = {key: F.softmax(calibrated_logits[Split.APP_TEST], dim=1)[:, 0] < thresholds[key] for key\n",
    "                              in thresholds.keys()}\n",
    "        optimal_app_test_preds = {\n",
    "            key: F.softmax(calibrated_logits[Split.APP_TEST], dim=1)[:, 0] < optimal_thresholds[key] for key in\n",
    "            optimal_thresholds.keys()}\n",
    "        # compute metrics values for predictions made using optimal app test thresholds\n",
    "        optimal_metrics = compute_all_metrics(mod_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                              mod_data[Kind.LOGITS][Split.APP_TEST], optimal_app_test_preds,\n",
    "                                              min_class=min_class, exact_priors=exact_prevalence,\n",
    "                                              estimated_priors=exact_prevalence)\n",
    "        # compute metrics values for predictions made using the other thresholds \n",
    "        dev_threshold_metrics = compute_all_metrics(mod_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                                    mod_data[Kind.LOGITS][Split.APP_TEST], new_app_test_preds,\n",
    "                                                    min_class=min_class, exact_priors=exact_prevalence,\n",
    "                                                    estimated_priors=exact_prevalence)\n",
    "        # append the computed metrics values to the results\n",
    "        for k in optimal_metrics.keys():\n",
    "            results[k].append(optimal_metrics[k])\n",
    "        for k in dev_threshold_metrics.keys():\n",
    "            results['reference ' + k.value].append(dev_threshold_metrics[k])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37bd7ff4ad3cc6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T17:40:48.484394Z",
     "start_time": "2024-08-21T16:11:56.130601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00% 24/24... rate=0.02 Hz, eta=0:00:00, total=0:19:25\n",
      " 100.00% 24/24... rate=0.04 Hz, eta=0:00:00, total=0:10:38\n",
      " 100.00% 24/24... rate=0.02 Hz, eta=0:00:00, total=0:18:45\n",
      " 100.00% 24/24... rate=0.04 Hz, eta=0:00:00, total=0:10:40\n",
      " 100.00% 24/24... rate=0.02 Hz, eta=0:00:00, total=0:18:43\n",
      " 100.00% 24/24... rate=0.04 Hz, eta=0:00:00, total=0:10:37\n"
     ]
    }
   ],
   "source": [
    "decision_results_list = []\n",
    "# iterate over calibration methods\n",
    "for cal in [CalibrationMethod.NONE, CalibrationMethod.AFFINE_REWEIGHTED, CalibrationMethod.AFFINE_ACC]:\n",
    "    # iterate over thresholding methods\n",
    "    for thresholding in [ThresholdingMethod.DEV_TEST, ThresholdingMethod.ARGMAX]:\n",
    "        # iterate over tasks\n",
    "        for t in ProgIter(binary_tasks):\n",
    "            for repeat in data:\n",
    "                _info = {'repeat': repeat, 'task': t, 'threshold': thresholding.value, 'calibration': cal.value}\n",
    "                _info.update(\n",
    "                    thresholds_accross_ir(task_data=data[repeat][t], calibration=cal, thresholding=thresholding))\n",
    "                decision_results_list.append(_info)\n",
    "decision_rule_df = pd.DataFrame(decision_results_list)\n",
    "decision_rule_df.to_pickle(RESULT_PATH / '24_uncertainty_decision_rule.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc181bbdbfd73939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:33:55.794679Z",
     "start_time": "2024-08-23T12:33:54.487343Z"
    }
   },
   "source": [
    "decision_rule_df = pd.read_pickle(RESULT_PATH / '24_uncertainty_decision_rule.pkl')\n",
    "metric_differences_list = []\n",
    "metrics = [Metric.ACCURACY, Metric.F1, Metric.MCC, Metric.BALANCED_ACC, Metric.EC_EST, Metric.EC_ADJUSTED]\n",
    "for thresholding in [ThresholdingMethod.ARGMAX, ThresholdingMethod.DEV_TEST]:\n",
    "    for cal in [CalibrationMethod.NONE, CalibrationMethod.AFFINE_REWEIGHTED]:\n",
    "        for repeat in data:\n",
    "            for ir_idx, ir in enumerate(IRS):\n",
    "                _info = {'repeat': repeat, 'calibration': cal.value, 'threshold': thresholding.value, 'ir': ir}\n",
    "                sub_df = decision_rule_df[\n",
    "                    (decision_rule_df['repeat'] == repeat) & (decision_rule_df['calibration'] == cal.value) & (\n",
    "                                decision_rule_df['threshold'] == thresholding.value)]\n",
    "                estimated_sub_df = decision_rule_df[(decision_rule_df['repeat'] == repeat) & (\n",
    "                            decision_rule_df['calibration'] == CalibrationMethod.AFFINE_ACC.value) & (\n",
    "                                                                decision_rule_df['threshold'] == thresholding.value)]\n",
    "                for metric in metrics:\n",
    "                    _vals = []\n",
    "                    iter_over_df = sub_df\n",
    "                    if metric == Metric.EC_EST:\n",
    "                        iter_over_df = estimated_sub_df\n",
    "                    for _, row in iter_over_df.iterrows():\n",
    "                        # use absolute difference since metrics are oriented differently \n",
    "                        # for example EC -> lower is better, ACC -> higher is better\n",
    "                        _vals.append(np.abs(row[metric][ir_idx] - row['reference ' + metric.value][ir_idx]))\n",
    "                    _info[metric] = np.mean(_vals)\n",
    "                metric_differences_list.append(_info)\n",
    "metric_differences = pd.DataFrame(metric_differences_list)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "12c274d7d3f65e38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:33:56.891046Z",
     "start_time": "2024-08-23T12:33:56.619958Z"
    }
   },
   "source": [
    "decison_rule_tables = {}\n",
    "for thresholding in [ThresholdingMethod.ARGMAX, ThresholdingMethod.DEV_TEST]:\n",
    "    for cal in [CalibrationMethod.NONE, CalibrationMethod.AFFINE_REWEIGHTED]:\n",
    "        table_entries = []\n",
    "        for ir in IRS:\n",
    "            train_uncertainty = {met: [] for met in metrics}\n",
    "            data_uncertainty = {met: [] for met in metrics}\n",
    "            sub_df = metric_differences[\n",
    "                (metric_differences.calibration == cal.value) & (metric_differences.ir == ir) & (\n",
    "                            metric_differences.threshold == thresholding.value)]\n",
    "            for repeat in sub_df['repeat'].unique():\n",
    "                vals = train_uncertainty if repeat < 10 else data_uncertainty\n",
    "                for met in metrics:\n",
    "                    vals[met].append(sub_df[sub_df['repeat'] == repeat][met].mean())\n",
    "            _info = {'ir': ir}\n",
    "            for met in metrics:\n",
    "                _info[met] = (f'{np.mean(train_uncertainty[met]):.3f} ± {np.std(train_uncertainty[met]):.3f} | '\n",
    "                              f'{np.mean(data_uncertainty[met]):.3f} ± {np.std(data_uncertainty[met]):.3f}')\n",
    "            table_entries.append(_info)\n",
    "        enum_map = {elem: elem.value for elem in list(Metric)}\n",
    "        df = pd.DataFrame(table_entries).rename(columns=enum_map).T\n",
    "        df = df.rename(columns=df.loc['ir'])\n",
    "        df.drop('ir', axis=0, inplace=True)\n",
    "        decison_rule_tables[(thresholding, cal)] = df"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "de6a9a01c705f02d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:33:59.298094Z",
     "start_time": "2024-08-23T12:33:59.288701Z"
    }
   },
   "source": [
    "t = ThresholdingMethod.ARGMAX\n",
    "c = CalibrationMethod.NONE\n",
    "print(f'Decision rule uncertainty for {t} and {c} (top left Fig. 9):')\n",
    "decison_rule_tables[(t, c)]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision rule uncertainty for ThresholdingMethod.ARGMAX and CalibrationMethod.NONE (top left Fig. 9):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                          1.0                            5.0   \\\n",
       "Accuracy         0.015 ± 0.003 | 0.015 ± 0.003  0.045 ± 0.007 | 0.045 ± 0.008   \n",
       "F1 Score         0.049 ± 0.009 | 0.058 ± 0.012  0.026 ± 0.005 | 0.030 ± 0.008   \n",
       "MCC              0.022 ± 0.004 | 0.025 ± 0.004  0.033 ± 0.005 | 0.036 ± 0.004   \n",
       "Bal. Accuracy    0.015 ± 0.003 | 0.015 ± 0.003  0.017 ± 0.004 | 0.016 ± 0.003   \n",
       "EC (est. prev.)  0.007 ± 0.001 | 0.006 ± 0.001  0.006 ± 0.005 | 0.005 ± 0.003   \n",
       "EC (dep. prev.)  0.015 ± 0.003 | 0.015 ± 0.003  0.045 ± 0.007 | 0.045 ± 0.008   \n",
       "\n",
       "                                          10.0  \n",
       "Accuracy         0.069 ± 0.009 | 0.068 ± 0.011  \n",
       "F1 Score         0.049 ± 0.007 | 0.053 ± 0.008  \n",
       "MCC              0.053 ± 0.006 | 0.056 ± 0.006  \n",
       "Bal. Accuracy    0.019 ± 0.004 | 0.020 ± 0.004  \n",
       "EC (est. prev.)  0.004 ± 0.003 | 0.003 ± 0.002  \n",
       "EC (dep. prev.)  0.069 ± 0.009 | 0.068 ± 0.011  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.015 ± 0.003 | 0.015 ± 0.003</td>\n",
       "      <td>0.045 ± 0.007 | 0.045 ± 0.008</td>\n",
       "      <td>0.069 ± 0.009 | 0.068 ± 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.049 ± 0.009 | 0.058 ± 0.012</td>\n",
       "      <td>0.026 ± 0.005 | 0.030 ± 0.008</td>\n",
       "      <td>0.049 ± 0.007 | 0.053 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.022 ± 0.004 | 0.025 ± 0.004</td>\n",
       "      <td>0.033 ± 0.005 | 0.036 ± 0.004</td>\n",
       "      <td>0.053 ± 0.006 | 0.056 ± 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bal. Accuracy</th>\n",
       "      <td>0.015 ± 0.003 | 0.015 ± 0.003</td>\n",
       "      <td>0.017 ± 0.004 | 0.016 ± 0.003</td>\n",
       "      <td>0.019 ± 0.004 | 0.020 ± 0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (est. prev.)</th>\n",
       "      <td>0.007 ± 0.001 | 0.006 ± 0.001</td>\n",
       "      <td>0.006 ± 0.005 | 0.005 ± 0.003</td>\n",
       "      <td>0.004 ± 0.003 | 0.003 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (dep. prev.)</th>\n",
       "      <td>0.015 ± 0.003 | 0.015 ± 0.003</td>\n",
       "      <td>0.045 ± 0.007 | 0.045 ± 0.008</td>\n",
       "      <td>0.069 ± 0.009 | 0.068 ± 0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "f8c0ed9319847f09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:34:00.128073Z",
     "start_time": "2024-08-23T12:34:00.120376Z"
    }
   },
   "source": [
    "t = ThresholdingMethod.ARGMAX\n",
    "c = CalibrationMethod.AFFINE_REWEIGHTED\n",
    "print(f'Decision rule uncertainty for {t} and {c} (top right Fig. 9):')\n",
    "decison_rule_tables[(t, c)]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision rule uncertainty for ThresholdingMethod.ARGMAX and CalibrationMethod.AFFINE_REWEIGHTED (top right Fig. 9):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                          1.0                            5.0   \\\n",
       "Accuracy         0.005 ± 0.001 | 0.005 ± 0.001  0.003 ± 0.000 | 0.003 ± 0.000   \n",
       "F1 Score         0.014 ± 0.002 | 0.018 ± 0.003  0.097 ± 0.011 | 0.090 ± 0.008   \n",
       "MCC              0.013 ± 0.004 | 0.015 ± 0.003  0.052 ± 0.009 | 0.047 ± 0.006   \n",
       "Bal. Accuracy    0.005 ± 0.001 | 0.005 ± 0.001  0.071 ± 0.005 | 0.065 ± 0.002   \n",
       "EC (est. prev.)  0.007 ± 0.001 | 0.006 ± 0.001  0.006 ± 0.005 | 0.005 ± 0.003   \n",
       "EC (dep. prev.)  0.005 ± 0.001 | 0.005 ± 0.001  0.003 ± 0.000 | 0.003 ± 0.000   \n",
       "\n",
       "                                          10.0  \n",
       "Accuracy         0.002 ± 0.000 | 0.002 ± 0.001  \n",
       "F1 Score         0.103 ± 0.011 | 0.112 ± 0.008  \n",
       "MCC              0.066 ± 0.008 | 0.075 ± 0.007  \n",
       "Bal. Accuracy    0.100 ± 0.005 | 0.103 ± 0.005  \n",
       "EC (est. prev.)  0.004 ± 0.003 | 0.003 ± 0.002  \n",
       "EC (dep. prev.)  0.002 ± 0.000 | 0.002 ± 0.001  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.005 ± 0.001 | 0.005 ± 0.001</td>\n",
       "      <td>0.003 ± 0.000 | 0.003 ± 0.000</td>\n",
       "      <td>0.002 ± 0.000 | 0.002 ± 0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.014 ± 0.002 | 0.018 ± 0.003</td>\n",
       "      <td>0.097 ± 0.011 | 0.090 ± 0.008</td>\n",
       "      <td>0.103 ± 0.011 | 0.112 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.013 ± 0.004 | 0.015 ± 0.003</td>\n",
       "      <td>0.052 ± 0.009 | 0.047 ± 0.006</td>\n",
       "      <td>0.066 ± 0.008 | 0.075 ± 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bal. Accuracy</th>\n",
       "      <td>0.005 ± 0.001 | 0.005 ± 0.001</td>\n",
       "      <td>0.071 ± 0.005 | 0.065 ± 0.002</td>\n",
       "      <td>0.100 ± 0.005 | 0.103 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (est. prev.)</th>\n",
       "      <td>0.007 ± 0.001 | 0.006 ± 0.001</td>\n",
       "      <td>0.006 ± 0.005 | 0.005 ± 0.003</td>\n",
       "      <td>0.004 ± 0.003 | 0.003 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (dep. prev.)</th>\n",
       "      <td>0.005 ± 0.001 | 0.005 ± 0.001</td>\n",
       "      <td>0.003 ± 0.000 | 0.003 ± 0.000</td>\n",
       "      <td>0.002 ± 0.000 | 0.002 ± 0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "41ee3d618364a4bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:34:00.833042Z",
     "start_time": "2024-08-23T12:34:00.827508Z"
    }
   },
   "source": [
    "t = ThresholdingMethod.DEV_TEST\n",
    "c = CalibrationMethod.NONE\n",
    "print(f'Decision rule uncertainty for {t} and {c} (bottom left Fig. 9):')\n",
    "decison_rule_tables[(t, c)]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision rule uncertainty for ThresholdingMethod.DEV_TEST and CalibrationMethod.NONE (bottom left Fig. 9):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                          1.0                            5.0   \\\n",
       "Accuracy         0.006 ± 0.001 | 0.007 ± 0.003  0.073 ± 0.010 | 0.072 ± 0.014   \n",
       "F1 Score         0.006 ± 0.002 | 0.007 ± 0.002  0.062 ± 0.006 | 0.062 ± 0.007   \n",
       "MCC              0.013 ± 0.003 | 0.017 ± 0.004  0.040 ± 0.006 | 0.043 ± 0.007   \n",
       "Bal. Accuracy    0.006 ± 0.001 | 0.007 ± 0.003  0.008 ± 0.003 | 0.009 ± 0.002   \n",
       "EC (est. prev.)  0.008 ± 0.003 | 0.010 ± 0.002  0.009 ± 0.009 | 0.005 ± 0.002   \n",
       "EC (dep. prev.)  0.006 ± 0.001 | 0.007 ± 0.003  0.004 ± 0.001 | 0.004 ± 0.000   \n",
       "\n",
       "                                          10.0  \n",
       "Accuracy         0.107 ± 0.012 | 0.103 ± 0.016  \n",
       "F1 Score         0.107 ± 0.006 | 0.110 ± 0.007  \n",
       "MCC              0.065 ± 0.007 | 0.066 ± 0.010  \n",
       "Bal. Accuracy    0.011 ± 0.002 | 0.012 ± 0.003  \n",
       "EC (est. prev.)  0.007 ± 0.004 | 0.006 ± 0.003  \n",
       "EC (dep. prev.)  0.003 ± 0.001 | 0.004 ± 0.001  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.006 ± 0.001 | 0.007 ± 0.003</td>\n",
       "      <td>0.073 ± 0.010 | 0.072 ± 0.014</td>\n",
       "      <td>0.107 ± 0.012 | 0.103 ± 0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.006 ± 0.002 | 0.007 ± 0.002</td>\n",
       "      <td>0.062 ± 0.006 | 0.062 ± 0.007</td>\n",
       "      <td>0.107 ± 0.006 | 0.110 ± 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.013 ± 0.003 | 0.017 ± 0.004</td>\n",
       "      <td>0.040 ± 0.006 | 0.043 ± 0.007</td>\n",
       "      <td>0.065 ± 0.007 | 0.066 ± 0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bal. Accuracy</th>\n",
       "      <td>0.006 ± 0.001 | 0.007 ± 0.003</td>\n",
       "      <td>0.008 ± 0.003 | 0.009 ± 0.002</td>\n",
       "      <td>0.011 ± 0.002 | 0.012 ± 0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (est. prev.)</th>\n",
       "      <td>0.008 ± 0.003 | 0.010 ± 0.002</td>\n",
       "      <td>0.009 ± 0.009 | 0.005 ± 0.002</td>\n",
       "      <td>0.007 ± 0.004 | 0.006 ± 0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (dep. prev.)</th>\n",
       "      <td>0.006 ± 0.001 | 0.007 ± 0.003</td>\n",
       "      <td>0.004 ± 0.001 | 0.004 ± 0.000</td>\n",
       "      <td>0.003 ± 0.001 | 0.004 ± 0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "19bd6130559f90c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:34:01.533386Z",
     "start_time": "2024-08-23T12:34:01.524072Z"
    }
   },
   "source": [
    "t = ThresholdingMethod.DEV_TEST\n",
    "c = CalibrationMethod.AFFINE_REWEIGHTED\n",
    "print(f'Decision rule uncertainty for {t} and {c} (bottom right Fig. 9):')\n",
    "decison_rule_tables[(t, c)]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision rule uncertainty for ThresholdingMethod.DEV_TEST and CalibrationMethod.AFFINE_REWEIGHTED (bottom right Fig. 9):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                          1.0                            5.0   \\\n",
       "Accuracy         0.006 ± 0.002 | 0.007 ± 0.003  0.072 ± 0.007 | 0.067 ± 0.009   \n",
       "F1 Score         0.007 ± 0.002 | 0.007 ± 0.001  0.061 ± 0.005 | 0.063 ± 0.007   \n",
       "MCC              0.014 ± 0.004 | 0.018 ± 0.004  0.039 ± 0.005 | 0.044 ± 0.007   \n",
       "Bal. Accuracy    0.006 ± 0.002 | 0.007 ± 0.003  0.008 ± 0.003 | 0.007 ± 0.002   \n",
       "EC (est. prev.)  0.008 ± 0.003 | 0.010 ± 0.002  0.009 ± 0.009 | 0.005 ± 0.002   \n",
       "EC (dep. prev.)  0.006 ± 0.002 | 0.007 ± 0.002  0.005 ± 0.001 | 0.004 ± 0.001   \n",
       "\n",
       "                                          10.0  \n",
       "Accuracy         0.101 ± 0.012 | 0.098 ± 0.010  \n",
       "F1 Score         0.107 ± 0.005 | 0.110 ± 0.009  \n",
       "MCC              0.063 ± 0.007 | 0.066 ± 0.008  \n",
       "Bal. Accuracy    0.010 ± 0.002 | 0.008 ± 0.002  \n",
       "EC (est. prev.)  0.007 ± 0.004 | 0.006 ± 0.003  \n",
       "EC (dep. prev.)  0.004 ± 0.001 | 0.004 ± 0.001  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.006 ± 0.002 | 0.007 ± 0.003</td>\n",
       "      <td>0.072 ± 0.007 | 0.067 ± 0.009</td>\n",
       "      <td>0.101 ± 0.012 | 0.098 ± 0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.007 ± 0.002 | 0.007 ± 0.001</td>\n",
       "      <td>0.061 ± 0.005 | 0.063 ± 0.007</td>\n",
       "      <td>0.107 ± 0.005 | 0.110 ± 0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.014 ± 0.004 | 0.018 ± 0.004</td>\n",
       "      <td>0.039 ± 0.005 | 0.044 ± 0.007</td>\n",
       "      <td>0.063 ± 0.007 | 0.066 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bal. Accuracy</th>\n",
       "      <td>0.006 ± 0.002 | 0.007 ± 0.003</td>\n",
       "      <td>0.008 ± 0.003 | 0.007 ± 0.002</td>\n",
       "      <td>0.010 ± 0.002 | 0.008 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (est. prev.)</th>\n",
       "      <td>0.008 ± 0.003 | 0.010 ± 0.002</td>\n",
       "      <td>0.009 ± 0.009 | 0.005 ± 0.002</td>\n",
       "      <td>0.007 ± 0.004 | 0.006 ± 0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (dep. prev.)</th>\n",
       "      <td>0.006 ± 0.002 | 0.007 ± 0.002</td>\n",
       "      <td>0.005 ± 0.001 | 0.004 ± 0.001</td>\n",
       "      <td>0.004 ± 0.001 | 0.004 ± 0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "38007999898c132a",
   "metadata": {},
   "source": [
    "## uncertainty with respect to performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2dfdfdab805ed18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:34:12.201858Z",
     "start_time": "2024-08-23T12:34:12.188104Z"
    }
   },
   "source": [
    "def metrics_across_ir(task_data, ir: float, calibration: CalibrationMethod = CalibrationMethod.NONE):\n",
    "    \"\"\" Computes metrics values on both development and test data of a given task and IR.\"\"\"\n",
    "    # scale prevalences in the deployment set according to imbalance ratio\n",
    "    app_test_logits, app_test_classes = scale_prevalences_ir(logits=task_data[Kind.LOGITS][Split.APP_TEST],\n",
    "                                                             classes=task_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                                             ir=ir)\n",
    "    # create a data dictionary with the modified deployment test set\n",
    "    mod_data = {Kind.LOGITS: {Split.DEV_CAL: task_data[Kind.LOGITS][Split.DEV_CAL],\n",
    "                              Split.DEV_TEST: task_data[Kind.LOGITS][Split.DEV_TEST],\n",
    "                              Split.APP_TEST: app_test_logits},\n",
    "                Kind.LABELS: {Split.DEV_CAL: task_data[Kind.LABELS][Split.DEV_CAL],\n",
    "                              Split.DEV_TEST: task_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                              Split.APP_TEST: app_test_classes}}\n",
    "\n",
    "    # extract the minority class for F1 computation\n",
    "    val_prevalences = torch.bincount(mod_data[Kind.LABELS][Split.DEV_CAL])\n",
    "    min_class = torch.argmin(val_prevalences).item()\n",
    "    max_class = torch.argmax(val_prevalences).item()\n",
    "    # catches case where for balanced task, min class was used as max class in scaling\n",
    "    if min_class == max_class:\n",
    "        min_class = 1\n",
    "    #compute the exact prevalence in the scaled deployment set\n",
    "    exact_prevalence = torch.bincount(mod_data[Kind.LABELS][Split.APP_TEST]) / len(\n",
    "        mod_data[Kind.LABELS][Split.APP_TEST])\n",
    "\n",
    "    # compute EC estimated separate - both calibration and EC adjustment rely on prevalence estimation\n",
    "    estimated_prevalence = torch.Tensor(adjust_priors_qp(torch.softmax(mod_data[Kind.LOGITS][Split.DEV_TEST], dim=1),\n",
    "                                                         mod_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                                         torch.softmax(mod_data[Kind.LOGITS][Split.APP_TEST], dim=1),\n",
    "                                                         mod_data[Kind.LABELS][Split.APP_TEST], method=ACC))\n",
    "    # calibrate logits and get estimated prevalence\n",
    "    if calibration == CalibrationMethod.AFFINE_REWEIGHTED:\n",
    "        prior = exact_prevalence\n",
    "    elif calibration == CalibrationMethod.NONE:\n",
    "        prior = None\n",
    "    else:\n",
    "        raise ValueError(f'invalid calibration method: {calibration}')\n",
    "    calibrated_logits = calibrate_logits_fast(data=mod_data, calibration=calibration, prior=prior)\n",
    "\n",
    "    # compute predictions on scaled deployment set and development test set according to argmax decision rule\n",
    "    new_app_test_preds = torch.argmax(calibrated_logits[Split.APP_TEST], dim=1)\n",
    "    dev_test_preds = torch.argmax(calibrated_logits[Split.DEV_TEST], dim=1)\n",
    "\n",
    "    #compute the metrics on the deployment and development sets\n",
    "    dep_metrics = compute_all_metrics(mod_data[Kind.LABELS][Split.APP_TEST], calibrated_logits[Split.APP_TEST],\n",
    "                                      new_app_test_preds,\n",
    "                                      min_class=min_class, exact_priors=exact_prevalence,\n",
    "                                      estimated_priors=exact_prevalence)\n",
    "    dev_metrics = compute_all_metrics(mod_data[Kind.LABELS][Split.DEV_TEST], calibrated_logits[Split.DEV_TEST],\n",
    "                                      dev_test_preds,\n",
    "                                      min_class=min_class, exact_priors=exact_prevalence,\n",
    "                                      estimated_priors=estimated_prevalence)\n",
    "    # recompute EC estimated separate since re-calibration has to rely on estimation as well!\n",
    "    if calibration == CalibrationMethod.AFFINE_REWEIGHTED:\n",
    "        calibrated_logits_est = calibrate_logits_fast(data=mod_data, calibration=calibration, prior=estimated_prevalence)\n",
    "        estimated_app_test_preds = torch.argmax(calibrated_logits_est[Split.APP_TEST], dim=1)\n",
    "        dep_metrics[Metric.EC_EST] = compute_metric(Metric.EC_ADJUSTED, mod_data[Kind.LABELS][Split.APP_TEST],\n",
    "                                                    estimated_app_test_preds, exact_priors=exact_prevalence,\n",
    "                                                    min_class=min_class)\n",
    "        estimated_dev_test_preds = torch.argmax(calibrated_logits_est[Split.DEV_TEST], dim=1)\n",
    "        dev_metrics[Metric.EC_EST] = compute_metric(Metric.EC_EST, mod_data[Kind.LABELS][Split.DEV_TEST],\n",
    "                                                    estimated_dev_test_preds,\n",
    "                                                    min_class=min_class, estimated_priors=estimated_prevalence)\n",
    "    # append metrics to the results dictionary\n",
    "    results = {}\n",
    "    for met in dep_metrics:\n",
    "        results[met] = dep_metrics[met]\n",
    "        results['reference ' + met.value] = dev_metrics[met]\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3cbef306bb400ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T20:48:06.732736Z",
     "start_time": "2024-08-22T20:46:27.280935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00% 24/24... rate=0.58 Hz, eta=0:00:00, total=0:00:41\n",
      " 100.00% 24/24... rate=0.41 Hz, eta=0:00:00, total=0:00:58\n"
     ]
    }
   ],
   "source": [
    "# compute metrics at different IRs for different calibration methods and estimated priors\n",
    "performance_assessment_list = []\n",
    "for cal in [CalibrationMethod.NONE, CalibrationMethod.AFFINE_REWEIGHTED]:\n",
    "    for t in ProgIter(binary_tasks):\n",
    "        for repeat in data:\n",
    "            for ir in IRS:\n",
    "                _info = {'repeat': repeat, 'task': t, 'calibration': cal.value, 'ir': ir}\n",
    "                _info.update(metrics_across_ir(task_data=data[repeat][t], ir=ir, calibration=cal))\n",
    "                performance_assessment_list.append(_info)\n",
    "performance_assessment_df = pd.DataFrame(performance_assessment_list)\n",
    "performance_assessment_df.to_pickle(RESULT_PATH / '24_uncertainty_metric.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "id": "941f8b984027bb7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:34:22.051045Z",
     "start_time": "2024-08-23T12:34:21.889973Z"
    }
   },
   "source": [
    "performance_assessment_df = pd.read_pickle(RESULT_PATH / '24_uncertainty_metric.pkl')\n",
    "metrics = [Metric.ACCURACY, Metric.F1, Metric.MCC, Metric.BALANCED_ACC, Metric.EC_EST, Metric.EC_ADJUSTED]\n",
    "# compute difference\n",
    "for metric in metrics:\n",
    "    performance_assessment_df[metric.value] = np.abs(\n",
    "        performance_assessment_df[metric] - performance_assessment_df['reference ' + metric.value])\n",
    "\n",
    "performance_assesment_tables = {}\n",
    "for cal in [CalibrationMethod.NONE, CalibrationMethod.AFFINE_REWEIGHTED]:\n",
    "    table_entries = []\n",
    "    for ir in IRS:\n",
    "        train_uncertainty = {met: [] for met in metrics}\n",
    "        data_uncertainty = {met: [] for met in metrics}\n",
    "        sub_df = performance_assessment_df[\n",
    "            (performance_assessment_df.calibration == cal.value) & (performance_assessment_df.ir == ir)]\n",
    "        for repeat in sub_df['repeat'].unique():\n",
    "            vals = train_uncertainty if repeat < 10 else data_uncertainty\n",
    "            for met in metrics:\n",
    "                vals[met].append(sub_df[sub_df['repeat'] == repeat][met.value].mean())\n",
    "        _info = {'ir': ir}\n",
    "        for met in metrics:\n",
    "            _info[met] = (f'{np.mean(train_uncertainty[met]):.3f} ± {np.std(train_uncertainty[met]):.3f} | '\n",
    "                          f'{np.mean(data_uncertainty[met]):.3f} ± {np.std(data_uncertainty[met]):.3f}')\n",
    "        table_entries.append(_info)\n",
    "    enum_map = {elem: elem.value for elem in list(Metric)}\n",
    "    df = pd.DataFrame(table_entries).rename(columns=enum_map).T\n",
    "    df = df.rename(columns=df.loc['ir'])\n",
    "    df.drop('ir', axis=0, inplace=True)\n",
    "    performance_assesment_tables[cal] = df"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "afdea3e2284779a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:34:27.302837Z",
     "start_time": "2024-08-23T12:34:27.294563Z"
    }
   },
   "source": [
    "performance_assesment_tables[CalibrationMethod.NONE]  # corresponds to figure 10 top row"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          1.0                            5.0   \\\n",
       "Accuracy         0.012 ± 0.002 | 0.012 ± 0.001  0.058 ± 0.010 | 0.061 ± 0.007   \n",
       "F1 Score         0.015 ± 0.002 | 0.016 ± 0.001  0.124 ± 0.008 | 0.122 ± 0.009   \n",
       "MCC              0.024 ± 0.004 | 0.025 ± 0.003  0.055 ± 0.008 | 0.053 ± 0.009   \n",
       "Bal. Accuracy    0.012 ± 0.002 | 0.012 ± 0.001  0.014 ± 0.003 | 0.014 ± 0.001   \n",
       "EC (est. prev.)  0.012 ± 0.002 | 0.013 ± 0.002  0.011 ± 0.003 | 0.013 ± 0.002   \n",
       "EC (dep. prev.)  0.012 ± 0.002 | 0.012 ± 0.001  0.012 ± 0.003 | 0.013 ± 0.001   \n",
       "\n",
       "                                          10.0  \n",
       "Accuracy         0.071 ± 0.012 | 0.074 ± 0.010  \n",
       "F1 Score         0.218 ± 0.013 | 0.210 ± 0.015  \n",
       "MCC              0.115 ± 0.012 | 0.106 ± 0.012  \n",
       "Bal. Accuracy    0.017 ± 0.003 | 0.015 ± 0.001  \n",
       "EC (est. prev.)  0.012 ± 0.002 | 0.014 ± 0.002  \n",
       "EC (dep. prev.)  0.013 ± 0.003 | 0.014 ± 0.002  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.012 ± 0.002 | 0.012 ± 0.001</td>\n",
       "      <td>0.058 ± 0.010 | 0.061 ± 0.007</td>\n",
       "      <td>0.071 ± 0.012 | 0.074 ± 0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.015 ± 0.002 | 0.016 ± 0.001</td>\n",
       "      <td>0.124 ± 0.008 | 0.122 ± 0.009</td>\n",
       "      <td>0.218 ± 0.013 | 0.210 ± 0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.024 ± 0.004 | 0.025 ± 0.003</td>\n",
       "      <td>0.055 ± 0.008 | 0.053 ± 0.009</td>\n",
       "      <td>0.115 ± 0.012 | 0.106 ± 0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bal. Accuracy</th>\n",
       "      <td>0.012 ± 0.002 | 0.012 ± 0.001</td>\n",
       "      <td>0.014 ± 0.003 | 0.014 ± 0.001</td>\n",
       "      <td>0.017 ± 0.003 | 0.015 ± 0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (est. prev.)</th>\n",
       "      <td>0.012 ± 0.002 | 0.013 ± 0.002</td>\n",
       "      <td>0.011 ± 0.003 | 0.013 ± 0.002</td>\n",
       "      <td>0.012 ± 0.002 | 0.014 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (dep. prev.)</th>\n",
       "      <td>0.012 ± 0.002 | 0.012 ± 0.001</td>\n",
       "      <td>0.012 ± 0.003 | 0.013 ± 0.001</td>\n",
       "      <td>0.013 ± 0.003 | 0.014 ± 0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "58b33fdc4e8a9d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T12:34:28.642233Z",
     "start_time": "2024-08-23T12:34:28.633156Z"
    }
   },
   "source": [
    "performance_assesment_tables[CalibrationMethod.AFFINE_REWEIGHTED]  # corresponds to figure 10 bottom row"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          1.0                            5.0   \\\n",
       "Accuracy         0.011 ± 0.002 | 0.012 ± 0.003  0.145 ± 0.007 | 0.145 ± 0.004   \n",
       "F1 Score         0.012 ± 0.002 | 0.013 ± 0.002  0.039 ± 0.004 | 0.041 ± 0.007   \n",
       "MCC              0.023 ± 0.003 | 0.023 ± 0.005  0.031 ± 0.002 | 0.029 ± 0.005   \n",
       "Bal. Accuracy    0.011 ± 0.002 | 0.012 ± 0.003  0.011 ± 0.002 | 0.011 ± 0.002   \n",
       "EC (est. prev.)  0.021 ± 0.008 | 0.026 ± 0.010  0.018 ± 0.005 | 0.031 ± 0.013   \n",
       "EC (dep. prev.)  0.011 ± 0.002 | 0.012 ± 0.003  0.006 ± 0.001 | 0.006 ± 0.001   \n",
       "\n",
       "                                          10.0  \n",
       "Accuracy         0.214 ± 0.008 | 0.212 ± 0.006  \n",
       "F1 Score         0.041 ± 0.005 | 0.047 ± 0.008  \n",
       "MCC              0.029 ± 0.006 | 0.038 ± 0.010  \n",
       "Bal. Accuracy    0.011 ± 0.002 | 0.012 ± 0.003  \n",
       "EC (est. prev.)  0.020 ± 0.007 | 0.029 ± 0.013  \n",
       "EC (dep. prev.)  0.004 ± 0.001 | 0.005 ± 0.001  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.011 ± 0.002 | 0.012 ± 0.003</td>\n",
       "      <td>0.145 ± 0.007 | 0.145 ± 0.004</td>\n",
       "      <td>0.214 ± 0.008 | 0.212 ± 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.012 ± 0.002 | 0.013 ± 0.002</td>\n",
       "      <td>0.039 ± 0.004 | 0.041 ± 0.007</td>\n",
       "      <td>0.041 ± 0.005 | 0.047 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.023 ± 0.003 | 0.023 ± 0.005</td>\n",
       "      <td>0.031 ± 0.002 | 0.029 ± 0.005</td>\n",
       "      <td>0.029 ± 0.006 | 0.038 ± 0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bal. Accuracy</th>\n",
       "      <td>0.011 ± 0.002 | 0.012 ± 0.003</td>\n",
       "      <td>0.011 ± 0.002 | 0.011 ± 0.002</td>\n",
       "      <td>0.011 ± 0.002 | 0.012 ± 0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (est. prev.)</th>\n",
       "      <td>0.021 ± 0.008 | 0.026 ± 0.010</td>\n",
       "      <td>0.018 ± 0.005 | 0.031 ± 0.013</td>\n",
       "      <td>0.020 ± 0.007 | 0.029 ± 0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC (dep. prev.)</th>\n",
       "      <td>0.011 ± 0.002 | 0.012 ± 0.003</td>\n",
       "      <td>0.006 ± 0.001 | 0.006 ± 0.001</td>\n",
       "      <td>0.004 ± 0.001 | 0.005 ± 0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
