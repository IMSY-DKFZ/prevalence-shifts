# Deployment under Prevalence Shifts

This repo serves as reproduction code for the paper "Deployment of Image Analysis Algorithms under Prevalence Shifts" 
see, [ArXiV](https://arxiv.org/abs/2303.12540). It will be published as conference paper at [MICCAI 2023](https://conferences.miccai.org/2023/en/).

## Overview

> DISCLAIMER: The mml dependency has not been published yet - this means so far the training part cannot be 
> reproduced publicly. We are working on it and release this dependency later. All evaluation and plotting scripts are 
> available. We provide three sample tasks with the produced predictions in /data/.

- [code structure](#code-structure)
- [installation](#installation)
- [image data preparation](#image-data-preparation)
- [model training and prediction generation](#training-and-predictions)
- [experiments and figures](#experiments-and-figures)


## code structure

The code of this repository is structured as follows in `src`:

 - `mml-plugin` implements a [`mml`](https://git.dkfz.de/imsy/ise/mml) plugin to re-distribute samples within a task according to our needs
 - `prev` contains definitions and routines that are shared through our experiments
 - the notebooks `1_...` to `5_...` contain the steps to reproduce our experiments

## installation

 > DISCLAIMER: mml is not yet public. Please install only the dependencies from requirements.txt!

 - create a virtualenv with conda and install python 3.10

```commandline
conda update -n base -c defaults conda
conda create --yes --name prev python=3.10
conda activate prev
```

 - install [mml-core](https://imsy.pages.dkfz.de/ise/mml/install.html#virtual-environment) and [mml-data plugin](https://imsy.pages.dkfz.de/ise/mml/api/plugins/data.html)

```commandline
pip install --index-url https://mmlToken:<personal_access_token>@git.dkfz.de/api/v4/projects/89/packages/pypi/simple mml-core==0.11.0
pip install mml-data==0.2.1 --index-url https://__token__:<your_personal_token>@git.dkfz.de/api/v4/projects/89/packages/pypi/simple
```

 - install local prevalence plugin and other requirements

```commandline
git clone git@git.dkfz.de:imsy/ise/prevalences.git
cd prevalences
pip install -r requirements.txt
cd src/mml_plugin/prevalences
pip install .
```

 - install the fonts (http://mirrors.ctan.org/fonts/newcomputermodern/otf/NewCM10-Regular.otf)
 - setup environment variables for `mml`

```commandline
cd ../../..
mml-env-setup
nano mml.env  # modify at least MML_DATA_PATH, MML_RESULTS_PATH and MML_LOCAL_WORKERS accordingly 
pwd | conda env config vars set MML_ENV_PATH=$(</dev/stdin)/mml.env
conda activate prev
```

## image data preparation

> DISCLAIMER: This section requires mml which is not yet public.

- the data and predictions generation process in handled with the `mml` framework
- the commands to leverage `mml` are generated in `1_generate_predictions.ipynb` and stored in 
  - `output_create.txt` for data download / task generation
  - `output_tag.txt` for the splitting of tasks according to the experiments
- if the commands shall be run on some external infrastructure (like a GPU cluster) the `1_generate_predictions.ipynb` contains configuration possibilities to adapt the three txt files
- the commands can be run locally by `bash output_XXX.txt` or remotely by `ssh user@host 'bash -s' < output_XXX.txt`, more precisely run in order

```commandline
bash src/output_create.txt
bash src/output_tag.txt
```

## training and predictions

> DISCLAIMER: This section requires mml which is not yet public.

- once more `mml` is leveraged for this step and the commands are generated in `1_generate_predictions.ipynb`
- this time the file is `output_predict.txt` and can be adapted as mentioned before
- keep in mind that this incorporates 90 training+prediction pipelines and takes some time to complete

```commandline
bash src/output_predict.txt
```

## experiments and figures

> DISCLAIMER: Since mml is not yet public we provide some sample predictions in /data.

- navigate to the top level folder named `data` and store the project folders generated by the previous commands in there, more precisely
  - locate your `MML_RESULTS_PATH` as provided in the [installation](#installation)
  - within search the project folders (default: `mic23_predictions_reproduce_0`, `mic23_predictions_reproduce_1` and `mic23_predictions_reproduce_2`)
  - copy those to the `data` folder next to `src`
- now you can load the predictions inside the jupyter notebooks, they should run straight forward and produce the figures in `results`, next to `src` and `data`

Notebooks:

- `2_plot_examples.ipynb` - overview figure
- `3_exp_1_calibration.ipynb` - calibration experiment
- `4_exp_2_decision_rule.ipynb` - threshold experiment
- `5_exp_3_validation_metrics.ipynb` - metric experiment
